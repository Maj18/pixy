{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import allel\n",
    "import zarr\n",
    "import numcodecs\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "import argparse, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--version] --stats {pi,dxy,pi_dxy} --vcf\n",
      "                             [VCF] --zarr [ZARR] [--populations [POPULATIONS]]\n",
      "                             [--window_size [WINDOW_SIZE]]\n",
      "                             --snp_filter_expression [SNP_FILTER_EXPRESSION]\n",
      "                             --invariant_filter_expression\n",
      "                             [INVARIANT_FILTER_EXPRESSION] [--out [OUT]]\n",
      "\n",
      "pixy: senisbly calculate pi and/or dxy from a VCF containing variant and\n",
      "invariant sites\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --version             show program's version number and exit\n",
      "  --stats {pi,dxy,pi_dxy}\n",
      "                        Which stats to to calulate from the VCF (pi, dxy, or\n",
      "                        both)\n",
      "  --vcf [VCF]           Path to the input VCF\n",
      "  --zarr [ZARR]         Folder in which to build the Zarr database\n",
      "  --populations [POPULATIONS]\n",
      "                        Path to the populations file\n",
      "  --window_size [WINDOW_SIZE]\n",
      "                        Window size in base pairs over which to calculate\n",
      "                        pi/dxy\n",
      "  --snp_filter_expression [SNP_FILTER_EXPRESSION]\n",
      "                        A comma separated list of filters (e.g. DP>=10,GQ>=20)\n",
      "                        to apply to SNPs\n",
      "  --invariant_filter_expression [INVARIANT_FILTER_EXPRESSION]\n",
      "                        A comma separated list of filters (e.g.\n",
      "                        DP>=10,RGQ>=20) to apply to invariant sites\n",
      "  --out [OUT]           Path to the output file\n"
     ]
    }
   ],
   "source": [
    "# parse the command line arguements\n",
    "# - validate the arguements \n",
    "# - throw errors if requiremabents are missing\n",
    "# - validate the filter strings\n",
    "\n",
    "#pi_dxy --pi --dxy\\ # must include at least 1 of pi and/dxy \n",
    "#--vcf allsites.vcf.gz \\ # required\n",
    "#--zarr path/to/zarr \\  # default to the vcf folder\n",
    "#--populations popfile.txt \\ # only required for dxy\n",
    "#--window_size 10000 \\ # not required, defaults to whole genome\n",
    "#--snp_filter_expression \"DP>=10, GQ>=20, FS>2\" \\ # required\n",
    "#--monomorphic_filter_expression \"DP>=10, RGQ>=20\" \\ # required\n",
    "#--out pi_dxy_out.txt # default to vcf path + suffix\n",
    "\n",
    "# https://stackoverflow.com/questions/40001892/reading-named-command-arguments\n",
    "# example:\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='pixy: senisbly calculate pi and/or dxy from a VCF containing variant and invariant sites')\n",
    "\n",
    "parser.add_argument('--version', action='version', version='%(prog)s 1.0')\n",
    "parser.add_argument('--stats', choices=['pi', 'dxy', 'pi_dxy'], help='Which stats to to calulate from the VCF (pi, dxy, or both)', required=True)\n",
    "parser.add_argument('--vcf', type=str, nargs='?', help='Path to the input VCF', required=True)\n",
    "parser.add_argument('--zarr', type=str, nargs='?', help='Folder in which to build the Zarr database', required=True)\n",
    "parser.add_argument('--populations', type=str, nargs='?', help='Path to the populations file')\n",
    "parser.add_argument('--window_size', type=int, nargs='?', help='Window size in base pairs over which to calculate pi/dxy')\n",
    "parser.add_argument('--snp_filter_expression', type=str, nargs='?', help='A comma separated list of filters (e.g. DP>=10,GQ>=20) to apply to SNPs', required=True)\n",
    "parser.add_argument('--invariant_filter_expression', type=str, nargs='?', help='A comma separated list of filters (e.g. DP>=10,RGQ>=20) to apply to invariant sites', required=True)\n",
    "parser.add_argument('--out', type=str, nargs='?', help='Path to the output file')\n",
    "\n",
    "parser.print_help()\n",
    "\n",
    "# pull out varizbles from the parsed args\n",
    "args = parser.parse_args('--stats pi_dxy --vcf test.vcf --zarr test/path/ --populations path/to/popfile.txt --snp_filter_expression DP>=10,GQ>=20,FS>2 --invariant_filter_expression DP>=10,RGQ>=20 --out pi_out.txt'.split())\n",
    "# sim_args = parser.parse_args()\n",
    "\n",
    "if (args.populations is None) and ((args.stats == 'dxy' or args.stats == 'pi_dxy')):\n",
    "    parser.error(\"--stats dxy and --stats pi_dxy requires --populations path/to/popfile.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(invariant_filter_expression='DP>=10,RGQ>=20', out='pi_out.txt', populations='path/to/popfile.txt', snp_filter_expression='DP>=10,GQ>=20,FS>2', stats='pi_dxy', vcf='test.vcf', window_size=None, zarr='test/path/')\n",
      "DP>=10,RGQ>=20\n"
     ]
    }
   ],
   "source": [
    "print(args)\n",
    "\n",
    "print(args.invariant_filter_expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating inputs\n",
    "\n",
    "# STEP 1 checking the vcf:\n",
    "# - check if sci-kit allele can do this\n",
    "# - check for contig info\n",
    "# - alternatively use position vector\n",
    "# - check for invariant sites and throw and error if they dont exist\n",
    "\n",
    "# STEP 2 validate the population file\n",
    "# - format is IND POP\n",
    "# - throw an error if individuals are missing from VCF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the data \n",
    "\n",
    "# - extracting the filtration values from the filter strings\n",
    "# - applying the filter to the whole dataset\n",
    "# - also filter out biallelic snps\n",
    "# - check to see there is any data left\n",
    "# - print warning for low data* think more about this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data:\n",
    "chromosome = \"chrX\"\n",
    "vcf_path = '/Users/Katharine Korunes/Documents/Dxy_test_data/chrX_36Ag_allsites.vcf.gz'\n",
    "zarr_path = '/Users/Katharine Korunes/Documents/Dxy_test_data/chrX_36Ag_allsites.zarr'\n",
    "# inspect the zarr data\n",
    "callset = zarr.open_group(zarr_path, mode='r')\n",
    "callset.tree(expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For accessing just the GT calls\n",
    "gt_zarr = callset[chromosome + '/calldata/GT']\n",
    "gt = allel.GenotypeArray(gt_zarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method (VariantChunkedTable) works, but is obselete -- trying to get new method working\n",
    "variants = allel.VariantChunkedTable(callset[chromosome]['variants'], \n",
    "                                    names=['POS', 'REF', 'ALT', 'DP', 'FS','MQ', 'QD', 'is_snp','numalt'],\n",
    "                                     index='POS')\n",
    "\n",
    "# This seems like it should work, but hasn't worked with any of the types of input we tried:        \n",
    "#variants = allel.VariantTable(callset)\n",
    "\n",
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse these variables from the CLI\n",
    "snpDP = 10 #DP>=10, \n",
    "snpGQ = 20 #GQ>=20\n",
    "snpFS = 2 #FS>2\n",
    "refDP = 10 #DP>=10 - monomorphic sites\n",
    "refRGQ = 20 #RGQ>=20 - monomorphic sites\n",
    "\n",
    "#Step 1: Use a boolean array to parse variants from monomorphic sites, so we can filter them separately\n",
    "snp_select = variants.eval('is_snp')[:]\n",
    "snp_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Use the above step to separate invariant and variant sites\n",
    "# Variant sites are where snp_select = True\n",
    "variants_only = gt.compress(snp_select, axis=0)\n",
    "variants_only\n",
    "# ideally, the compress() method should work on the VariantTable (just as it works on the GT data) -- having trouble with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invariant sites are where snp_select = False\n",
    "ref_only = gt.compress(~snp_select, axis=0)\n",
    "ref_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Once variant/invariant are separated, apply filter expressions\n",
    "\n",
    "# We can use \"numalt\" to check if biallelic!\n",
    "snp_filter_expression = \"(DP > {}) & (FS > {}) & (numalt < 2)\".format(snpDP,snpFS)\n",
    "snp_filter_expression\n",
    "# We can evaluate complex filter expressions if we get the VariantTable format working:\n",
    "#variant_selection = variants.eval(snp_filter_expression)[:]\n",
    "#variant_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate pi\n",
    "\n",
    "# for loop wrapper for pi calcuation\n",
    "# output looks like:\n",
    "\n",
    "# chromosome pos1 pos2 no_differences no_comparisons no_missing pi_1 pi_2 dxy\n",
    "# chromosome pos1 pos2 no_differences no_comparisons no_missing pi\n",
    "# chromosome pos1 pos2 no_differences no_comparisons no_missing dxy\n",
    "\n",
    "# check if pi output makes sense\n",
    "# - are any pis/dxys all zero?\n",
    "# - check if # missing == (pos2 - pos1)\n",
    "# - check if everything was either compared or missing\n",
    "# - write out summary of program parameters file* think about how this should work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic functions for comparing the genotypes at each site in a region: counts differences out of sites with data\n",
    "\n",
    "#For the given region: return average pi, # of differences, # of comparisons, and # missing.\n",
    "# this function loops over every site in a region passed to it\n",
    "def tallyRegion(gt_region):\n",
    "    total_diffs = 0\n",
    "    total_comps = 0\n",
    "    total_missing = 0\n",
    "    for site in gt_region:\n",
    "        vec = site.flatten()\n",
    "        #now we have an individual site as a numpy.ndarray, pass it to the comparison function\n",
    "        site_diffs, site_comps, missing = compareGTs(vec)\n",
    "        total_diffs += site_diffs\n",
    "        total_comps += site_comps\n",
    "        total_missing += missing\n",
    "    if total_comps > 0:\n",
    "        avg_pi = total_diffs/total_comps\n",
    "    else:\n",
    "        avg_pi = 0\n",
    "    return(avg_pi, total_diffs, total_comps, total_missing)\n",
    "\n",
    "#Out of sites with data, count differences. \n",
    "#Return the number of differences, the number of comparisons, and missing data count.\n",
    "def compareGTs(vec):\n",
    "    # use gts to select only sites with data. \n",
    "    # counting missing data as a check, but it's implicit in the length of (gts)\n",
    "    gts = []\n",
    "    missing = 0\n",
    "    for x in vec:\n",
    "        if x in (0,1):\n",
    "            gts.append(x)\n",
    "        else:\n",
    "            missing += 1\n",
    "    c = Counter(gts)\n",
    "    #print(c)\n",
    "    diffs = c[1]*c[0]\n",
    "    comps = len(list(combinations(gts, 2)))        \n",
    "    return(diffs,comps,missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pi over a chosen window size\n",
    "pos = allel.SortedIndex(callset[chromosome + '/variants/POS'])\n",
    "\n",
    "#window size:\n",
    "w = 1000\n",
    "\n",
    "#Testing with a 10kb chunk, but can modify later to default to chromosome length\n",
    "y = w\n",
    "for x in range (1, 10000, w):\n",
    "    loc_region = pos.locate_range(x, y)\n",
    "    gt_region1 = allel.GenotypeArray(gt_zarr[loc_region])\n",
    "    avg_pi, total_diffs, total_comps, total_missing = tallyRegion(gt_region1)\n",
    "    print(\"Region:\", x , y, \",\", \"Region length:\", len(gt_region1))\n",
    "    print(\"Average pi:\", avg_pi)\n",
    "    print(\"Diffs, comps, missing:\", total_diffs, total_comps, total_missing, \"\\n\")\n",
    "    y += w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook pixy.ipynb to python\n",
      "[NbConvertApp] Writing 4002 bytes to pixy.py\n"
     ]
    }
   ],
   "source": [
    "# convert this notebook to a .py script\n",
    "!jupyter nbconvert --to=python pixy.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allel",
   "language": "python",
   "name": "allel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
